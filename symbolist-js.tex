% -----------------------------------------------
% Template for SMAC SMC 2013
% adapted and corrected from the template for SMC 2012, which was adapted from that of SMC 2011
% further updated for TENOR 2015, 2016, 2017 and 2018
% -----------------------------------------------

\documentclass{article}
\usepackage{tenor}
\usepackage{ifpdf}
\usepackage[english]{babel}
\usepackage{balance}

\input{js-code-format}
\input{json-format}
%\usepackage{listings}


%%%%%%%%%%%%%%%%%%%%%%%% Some useful packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% See related documentation %%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{amsmath} % popular packages from Am. Math. Soc. Please use the 
%\usepackage{amssymb} % related math environments (split, subequation, cases,
%\usepackage{amsfonts}% multline, etc.)
%\usepackage{bm}      % Bold Math package, defines the command \bf{}
%\usepackage{paralist}% extended list environments
%%subfig.sty is the modern replacement for subfigure.sty. However, subfig.sty 
%%requires and automatically loads caption.sty which overrides class handling 
%%of captions. To prevent this problem, preload caption.sty with caption=false 
%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}


\def\papertitle{Symbolist re-imagined: developing tools for user-defined bidirectional mapping}
\def\firstauthor{Rama Gottfried}
%\def\secondauthor{James Tsz-Him Cheung}
%\def\thirdauthor{Georg Hajdu}

\def\copyrightyear{2022}


\usepackage{xspace}
\def\symbolist{\textsc{symbolist}\xspace}
\def\drawsocket{\textsc{drawsocket}\xspace}
\def\uicontroller{\textit{ui\_controller}\xspace}
\def\iocontroller{\textit{io\_controller}\xspace}
\def\uiapiFunction{\textit{ui\_api}}
\def\uiapi{\textit{ui\_api}\xspace}
\def\ioapiFunction{\textit{io\_api}}
\def\ioapi{\textit{io\_api}\xspace}
\makeatletter
\newcommand{\verbatimfont}[1]{\renewcommand{\verbatim@font}{\ttfamily#1}}
\makeatother


%% Depending on the number of authors, set this variable accordingly for the copyright notice:
% \def\copyrightauthors{Author One}
\def\copyrightauthors{Rama Gottfried}
% \def\copyrightauthors{Author One, Author Two et al}

% adds the automatic
% Saves a lot of output space in PDF... after conversion with the distiller
% Delete if you cannot get PS fonts working on your system.

\def\oscfontsize{\tiny}


% pdf-tex settings: detect automatically if run by latex or pdflatex
\newif\ifpdf
\ifx\pdfoutput\relax
\else
   \ifcase\pdfoutput
      \pdffalse
   \else
      \pdftrue
\fi

\ifpdf % compiling with pdflatex
  \usepackage[pdftex,
    pdftitle={\papertitle},
    pdfauthor={\firstauthor},
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen; 
                     % especially useful if working with a big screen :-)
   ]{hyperref}
  %\pdfcompresslevel=9

  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are and their extensions so 
  %you won't have to specify these with every instance of \includegraphics
  \graphicspath{{./figures/}}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}

  \usepackage[figure,table]{hypcap}

\else % compiling with latex
  \usepackage[dvips,
    bookmarksnumbered, % use section numbers with bookmarks
    pdfstartview=XYZ % start with zoom=100% instead of full screen
  ]{hyperref}  % hyperrefs are active in the pdf file after conversion

  \usepackage[dvips]{epsfig,graphicx}
  % declare the path(s) where your graphic files are and their extensions so 
  %you won't have to specify these with every instance of \includegraphics
  \graphicspath{{./figures/}}
  \DeclareGraphicsExtensions{.eps}

  \usepackage[figure,table]{hypcap}
\fi

%setup the hyperref package - make the links black without a surrounding frame
\hypersetup{
    colorlinks,%
    citecolor=black,%
    filecolor=black,%
    linkcolor=black,%
    urlcolor=black
}


% Title.
% ------
\title{\papertitle}

\oneauthor
% \threeauthors
   {\firstauthor} { Hochschule f√ºr Music und Theater \\ Hamburg, Germany \\
     {\tt \href{mailto:rama.gottfried@hfmt-hamburg.de}{rama.gottfried@hfmt-hamburg.de}}}
% {\secondauthor} {University for Music and Theater \\ Hamburg, Germany  \\ 
%   {\tt \href{mailto:tsz.him.cheung@hfmt-hamburg.de}{tsz.him.cheung@hfmt-hamburg.de}}} 
% {\thirdauthor} {University for Music and Theater \\ Hamburg, Germany \\
%   {\tt \href{mailto:georg.hajdu@hfmt-hamburg.de}{georg.hajdu@hfmt-hamburg.de}}}



% ***************************************** the document starts here ***************
\begin{document}
%
\capstartfalse
\maketitle
\capstarttrue


% ABSTRACT
% fill in after finishing the paper
\begin{abstract}

maybe already start with history here, and then continue to symbolist?

  \symbolist is an in-development application for experimental notation, with the goal of creating a working environment for developing symbolic notation for multimedia which can be interpreted and performed by electronics. The program aims to provide an open play space, with tools for experimentation, and thinking visually about relationships between representation and interpretation in media performance. 
In the paper we discuss the evaluation and re-design of the application based on the need for a bi-directional mapping framework for working with symbolic notation and its corresponding data representations.

\end{abstract}


% INTRO
% not sure what should go here, or how in detail to go
% I guess:
% why did I make it, what is it, breifly discuss some of the steps

\section{Background}\label{sec:background}

The origins of the \symbolist project can be traced back to 2011 when I was working on my PhD at UC Berkeley's Center for New Music and Audio Technologies (CNMAT). Around this time, I began composing in Adobe Illustrator using a plugin called Scriptographer\footnote{https://scriptographer.org/}, which allowed the user to create new drawing tools with Javascript that could then be used like a brush in Illustrator; much like you would use mouse interaction in programs like Processing\footnote{https://processing.org/}. This was perfect for my composition needs working with extended instrumental techniques, since I could then create a notation of whatever I needed and code it into a reusable graphic template, that could then be manipulated graphically in Illustrator. Additionally, since you had access to the mouse movement, you could create interactions that could be used to compose, for instance I often used what I called a ``notehead-line'', which was a note-head of some shape, with a line extending out from it to show its duration. Using Scriptographer, I was able to create a user interface where after clicking down on the Illustrator canvas to draw the note-head, I could then track the mouse drag to determine the end of the duration line.

Scriptographer's drawing API provided a set of basic vector primitives and grouping methods that closely parallel the objects found in Scalable Vector Graphics (SVG) format~\footnote{https://www.w3.org/TR/SVG11} which is well supported in Adobe Illustrator. Using grouping methods in Scriptographer, you could create hierarchies of objects that would then be created in Illustrator as grouped objects visible as nested folders in the layers menu.

Around the same time at CNMAT, I was deeply involved with developing approaches to instrument design using Open Sound Control (OSC)~\cite{wright:osc} as a principle data structuring encoding. One day, while working with Scriptographer, I had saved a score in Illustrator as SVG format and accidentally opened the SVG file in a text editor. In the SVG file I noticed that all of my graphic objects where there in a human readable format, and closely resembled the kind of nested objects that we were working on at CNMAT in the Odot library\cite{maccallum2015dynamic}. This gave me the idea that I could maybe translate the SVG information into OSC and then ``perform'' the OSC score in much the same way as you would a stream of OSC coming from a sensor based instrument. The first tests seemed promising, and so I logged it away for possible future use.

Soon after, studying high-resolution spatial audio rendering systems, I needed to find a way to compose spatial movements in a way that would connect with my graphic compositional practice. After some initial experiments using Blender\footnote{https://www.blender.org/} to compose movements which could then be parsed via Python and sent out over OSC, I was confronted by a perceptual gap between common practice notation and 3D representation, which seemed too difficult to address in the limited time I had, and so I fell back on using automation controls in Ableton Live\footnote{https://www.ableton.com/en/} and sending OSC to control the movements using Max for Live\footnote{https://cycling74.com/}. This was functional, but had the limitation of forcing the composer to separate each data parameter into separate streams of data, whereas in a symbolic representation different graphic attributes can indicate different elements of the data at the same time. Following these experiences~\cite{gottfried2013studies} I later returned to the SVG-OSC transcoding idea, and produced the first working model which was presented at the 2015 TENOR conference~\cite{gottfried2015svg}.

In the meantime, the Scriptographer project was abandoned by its developers after Adobe drastically changed their plugin API in version CS6. Rather than recode the project from scratch, the authors went on to create Paper.js\footnote{http://paperjs.org/}, which has some similarities with Scriptographer, but is more closely related to Processing, since it no longer is bound to the Illustrator application environment. This created a stumbling block for the SVG-OSC work, since I was relying on Scriptographer and its link to Illustrator as primary tools for the creation of easy to print scores for musicians to perform with. Additionally, working with preliminary OSC transcoding tests I found that it was becoming somewhat complicated to parse complex hierarchies of symbols in order to play them back via OSC streams, and so in 2017 I began work in collaboration with OpenMusic developer Jean Bresson~\cite{bresson2011om}, through a Ircam-ZKM Musical Research Residency towards the goal of creating a system that could replace the Scriptographer/Illustrator approach that I had developed so far.

\subsection*{Symbolist JUCE}\label{sec:juce_version}

The first version of \symbolist was created in 2018 as a standalone JUCE\footnote{https://juce.com/} application, which provided the basic tools for drawing vector graphics, and query system that allowed \symbolist to be used as a lookup table for OSC stream playback~\cite{gottfried2018symbolist}.

Working in JUCE seemed practical since it has a wide user base, and is used for audio plugins as well as Max and Ableton Live applications. However, working with SVG in JUCE proved to be an issue, since JUCE does not support the full SVG specification\footnote{https://forum.juce.com/t/complex-svg-files-fail-to-load-properly/26917/16}. However, a greater turning point in the project occurred towards the end of residency as I was thinking about how to simplify the process of using the SVG data for controlling digital processes.

\subsection*{Clefs and Bidirectional Mapping}\label{sec:bidirectional_mapping}

In the first version of \symbolist as in the original SVG-OSC implementation, the graphic data needed to be interpreted by the application that received the data. Using Odot I would parse the graphic OSC information coming in from \symbolist, and then mapped the data to other processes, for instance synthesis parameters, or coordinates for spatial rendering. This process of interpretation requires that the interpreter know the context of the graphic objects. For example, that a circle is a note-head and not a rhythmic dot, and so on. Like keys on the axises of a graphic plot of information, musical symbols, meter, staff-lines and clefs, indicate to the reader how they should interpret the notes and rhythmic symbols written on the staff.

The following phase of \symbolist development continued as I began work at the Hamburg University of Music and Theater, working with Georg Hajdu in the Innovative Hochschule project. Continuing on this idea of the \textit{clef} as being a plot ``key'' for interpretation, I began work on developing a system for \symbolist that would allow the user to create mappings internally within \symbolist. The idea being that since the data is already in hierarchical format in the application data structure, it makes sense to be able to interpret the data internally, and then stream OSC containing the pre-interpreted data rather than the raw graphic information which required complex parsing of the graphic hierarchies to rebuild the symbolic hierarchies that were visible to the eye based on traditional common practice notation. Further, I realized that what \symbolist \textit{really} needed was a system for \textit{bi-directional mapping}, where graphic data is interpreted as symbolic data with semantic meaning, and inversely, that the user should also be able to send symbolic semantic data to \symbolist, which could then translate the semantic data to a graphic representation. In 2018 I began working to implement this idea into the JUCE version, but soon needed to switch tracks to focus on a different notation issue for a project at the Innovative Hochschule, developing a platform for realtime networked score display.

\subsection*{Drawsocket and Symbolist JS}\label{sec:drawsocket}

At the end of 2018, and first half of 2019 we developed a \drawsocket, a server/client system providing a framework for realtime dynamic notation, using web-browsers for graphic rendering~\cite{gottfried2019drawsocket, hajdu2005quintet}. Based in node.js and standard web technologies of HTML, SVG, CSS, and Javascript\footnote{And by extension, provides access to other media via WebAudio, WebGL, etc.}, \drawsocket is essentially an OSC wrapper~\cite{freed2014io} for the web-browser, providing a homogeneous message API for the creating and realtime manipulation of browser elements.

Returning to \symbolist after the completion of the first concerts with \drawsocket, I began wondering if perhaps the framework of \symbolist needed to be re-designed from the prospective of bi-directional mapping, since I realized that this was probably the most important part of the graphic-data relationship that the system is based on. Working on \drawsocket showed me that SVG is very well integrated into modern browser display rendering, and having been working with node.js, I decided to see how fast it would be to implement a proof of concept using Electron.js\footnote{https://www.electronjs.org/} which is a cross-platform application development, using a node.js sever and Chrome as a front-end. While developing \drawsocket, I did some study into frameworks such like React\footnote{https://reactjs.org/} which provide object oriented ways of handling graphic interfaces, not unlike the approaches used in JUCE, however after working in JUCE, I wanted something lightweight and simple to start with.

Using \drawsocket as a frontend, and node.js for the backend I found that I was able to get up and running very quickly with Electron, and so decided to continue \symbolist development in this direction, bringing the experience gained from the JUCE version to the creation of a deeper structure for the creation of symbol interpretations that integrate into the graphic manipulation of symbolic data. 

% screenshot
\begin{figure*}[ht!]
\centering
\includegraphics[width=2\columnwidth]{symbolist.png}
\caption{ \symbolist screenshot, showing some different types of staves, and editing capabilities.
\label{fig:screenshot}}
\end{figure*}


%% Implementations
%\section{Implementation}\label{sec:implementations}
%
%Electron\footnote{https://www.electronjs.org/} version (node + chrome w/ special electron IPC)
%Max version (node + jweb + Max patch for IPC)


\begin{figure*}[ht!]
\centering
\includegraphics[width=2\columnwidth]{symbolist-architecture2.pdf}
\caption{ \symbolist architecture.
\label{fig:architecture}}
\end{figure*}

% Application Structure
\section{Application Structure}\label{sec:application_structure}

The new Javascript implementation of \symbolist is organized as a server-client model, comprising of:

\begin{enumerate}\itemsep0pt 
\item The \textit{editor}, a browser-based user interface client which displays the graphic representation of the data, and allows the user to edit and create new data objects through graphic interaction. The \uicontroller runs in the browser (see Figure~\ref{fig:architecture}), and handles interaction via a library of definition scripts which specify mappings to and from data and graphics formats, as well as other tools and interactions.

\item The \textit{symbolist server} runs in node.js (either in the context of Electron, or in Max's node.script object) and is comprised of: 
\begin{itemize}\itemsep0pt 

\item A HTTP web-server which serves the editor webpage, and manages messages between the \uicontroller and the \iocontroller via WebSocket connection, as well as handling operating system commands like reading and writing files.

\item  The \iocontroller script runs inside the \textit{symbolist server} and handles input and output from external sources via OSC over a UDP socket which can be used for a wide range of actions. The \iocontroller additionally maintains the central \textit{score} database in its semantic data format (described below).
\end{itemize}
\end{enumerate}

%Since the system is now based on a web-server / client model, we are able to also use Max's \textit{node.script} object, to run the sever from within Max, and additionally have created a version that runs in a \textit{jweb} object for use fully within Max.

\subsection*{Interprocess messaging syntax} 
\symbolist uses a \textit{key/val} message syntax for OSC and JSON interprocess communication developed in \drawsocket (discussed further in sections~\ref{sec:user_methods} and \ref{sec:osc_input}), where a \textit{key} address is used a keyword to signal which routine should interpret the message, and the \textit{val} address contains an object (or array of objects) to be processes.


%The \iocontroller holds a copy of the score in its semantic data format (described below), and loads a library of user scripts shared with the \uicontroller which define the mapping to (and potentially from) other media sources. 
%
%The \iocontroller can also be used to translate the score into other formats that can be performed by another sequencing tool or program like MaxMSP.
%

\section{Graphical Authoring and Interaction}\label{sec:editor} %should this be before or after the application structure?

%the palette symbol system is interesting maybe, to discuss how you can ``enter into'' a symbol, and then the possible sub-elements populate the palette.

The graphic user interface of \symbolist (Figure~\ref{fig:screenshot}) is designed around the idea of symbol objects and containers. Graphic objects, or \textit{symbols}, are placed in \textit{container} references which define a framing used to interpret the meaning of the \textit{symbol}.

In order to maintain an open and un-opinionated approach to authoring tools, \symbolist tries not to specify how containers and symbols should look, act, or respond when you interact with them within the application. 
Rather, the interaction and meanings of the symbols are defined in a library of custom object \textit{definitions} which create these meanings through mapping semantic data to and from the graphic visualization. 
Definitions can be shared between users and provide a mechanism to setup tailored composition environments for different authoring situations.

%See below for more information about the API for creating symbol definitions. 

\subsection{Interface Components}\label{sec:interface_components}

%main interesting thing to talk about is the palette system

Since the application is programmed using web-brower technologies (JS/HTML/CSS/SVG) there are many ways to customize the layout, using CSS, or defining new object types. 
The default \symbolist graphic editor (Figure~\ref{fig:screenshot}) provides the basic mechanisms for user interaction, to create scores through the creation of hierarchical object relationships.
The main graphic components are:

\begin{itemize}\itemsep0pt 
\item 
\textit{Document view}: the top level view of the application window, containing the document, and side bar. Sliders are provided to offset the view of the document, as well as basic zoom functionality.
\item 
\textit{Palette}: a set of buttons on in the side bar of the program which display icons of the \textit{symbols} that have been defined for the current selected \textit{container}. 
\item 
\textit{Tools}: a set of buttons that open tools for custom computer-assisted generation of new symbols, and applying transformations to existing elements (e.g. alignment of multiple objects, or setting distributing objects, etc.)
\item 
\textit{Inspector}: a contextual menu for editing the semantic data of an object, which is then mapped to the graphic representation.
\item 
\textit{Menu bar}: (Electron version only) the menu bar at the top of the screen or window, which provides access to various application functions.
\end{itemize}

\subsection{Modes}\label{sec:modes}

In the process of working in \symbolist, the user will shift between different modes, each of which have user-definable behaviors in the definitions library.
The current modes are:
\begin{itemize}\itemsep0pt 
\item \textit{Palette}: clicking on an icon in the palette sidebar enables the user interaction assigned to the clicked symbol type.
\item \textit{Creation}: holding down the CMD key (Mac) enters \textit{creation mode}, telling \symbolist to create a new \textit{symbol} of the type selected in the palette, similarly this action may enable different types of user interaction, for example snapping the symbol to specified pixels, etc.
\item \textit{Selection}: clicking on a pre-existing \textit{symbol} in the document will \textit{select} the object, which notifies a callback in the definition script for possible interaction.
\item \textit{Edit}: if a user has selected an object and then types the letter [e], \symbolist will attempt to enter \textit{edit mode} if there is one defined in the symbol definition script. This is useful for example in the case of a bezier curve; entering \textit{edit mode} could make visible the handles for the curve for editing.
\item \textit{Inspector}: if a user has selected an object and then types the letter [i], an inspector window appears showing the \textit{semantic data} corresponding to the symbol's graphical information (datatypes are discussed further in section~\ref{sec:representation} below).
\end{itemize}

% UX -- maybe take this out, or integrate it with the above to save space
%
%\subsection{User Experience}\label{sec:ux}
%
%On entering the application, the editor loads a score or configuration file from the default load folder, which sets the top-level page setup and palette options. A typical sequence of creating a score might be as follows:
%\begin{enumerate}\itemsep0pt
%\item The user opens a workspace, with one or more default \textit{container symbols} displayed on the screen, for example an empty rectangle which is like a piece of paper.
%\item Selecting the ``paper'' container rectangle, the user then selects the container as the new \textit{context} by pressing the [s] key (or from the application menu).
%\item Once setting the context, the palette toolbar is populated with icons of symbols that are defined with the selected container context type.
%\item Clicking on one of the palette toolbar symbol icons, puts the interface into \textit{palette mode}, where the mouse interaction is now designed for use with this specific symbol type.
%\item Holding the Mac CMD button enters \textit{creation mode} and by default creates a preview of the symbol how it will appear when you click, and some text is displayed near the mouse that shows the semantic data associated with the graphic representation.
%\item After clicking the symbol is placed in the container.
%\item Depending on the symbol type, you may be able to drag the symbol to a new place in the container, and the associated data is updated as a result.
%\item Selecting the symbol and hitting the [i] button, brings up the inspector window, where you can edit the data and see the graphics updated in response.
%\item Selecting and pressing the [e] button enters \textit{edit mode} which is a modal context where different user interaction could change the values of the symbol in different ways. For example in edit mode you might be able to rotate an object in a certain way, or be able to visualize different connections to the graphic representation to other elements of the score which are not usually highlighted in the score view.
%\end{enumerate}
%

\section{Data Representation}\label{sec:representation}

At the heart of \symbolist are two parallel forms of information expression: \textit{semantic data} and \textit{graphic representation} (Figure~\ref{fig:graphic-representation}).

\textit{Semantic data} specifies the various attributes of information about a symbolic object, in terms of the object's meaning to the author. 
For example, the meaningful attributes of a \textit{note} object might be information about pitch and duration, or a \textit{point} object might contain x, y, and z values corresponding to the point's location in 3D space. In \symbolist \textit{semantic data} is thought of as the main holder of information in the system, which through grouping and hierarchical arrangement can be used to represent scores or other types of data structures.

The \textit{graphic representation} of the information is a visual expression of the semantic data, which is open in nature. The aim of \symbolist is to provide an agnostic framework for developing visual, symbolic, or other unknown representations of semantic data for use in multimedia composition practice; and so, one of the main functions of the new version of the software is to facilitate the creation of mapping relationships between different representations of the data.


\begin{figure}[ht!]
\centering
\includegraphics[width=1\columnwidth]{graphic-representation.pdf}
\caption{\textit{data} vs \textit{graphic} representation of the same information.
\label{fig:graphic-representation}}
\end{figure}



\section{Symbols}\label{sec:symbols}

In \symbolist terminology, a \textit{symbol} is an instance of a symbolic representation of data that connects the semantic, graphic, and possibly other media types of expression together as a multifaceted unit.
Each \textit{symbol} is defined as a \textit{class} of object, which specifies the symbol's data structure and UI interaction, and data mapping to different representational contexts.

\section{Semantic Data Format}\label{sec:format}

Within the \symbolist application, semantic data is stored as javascript objects, and read/written in JSON format~\footnote{https://www.json.org/json-en.html}, which is transcoded to and from OSC for inter-application communication.

The main attributes used in \symbolist semantic data objects are:

\begin{itemize}\itemsep0pt 
\item \textit{id}: a unique identifier name (required).
\item \textit{class}: a reference to the definition of the object type in the user-definition library (required).
\item \textit{contents}: an array of child objects that a parent container object might hold (required for container symbols).
\end{itemize}

In addition to the required \textit{id} and \textit{class} attributes, symbol objects may include any number of other \textit{attributes}\footnote{The term \textit{attribute} is used here interchangeably with properties, parameters, aspects, etc.} of the symbol (\textit{pitch}, \textit{amplitude}, etc.). For example a simple semantic object written in JSON might look like:

\begin{lstlisting}[
belowskip=-2 \baselineskip,
  mathescape,
  columns=fullflexible,
  breaklines=true,
  basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont,
]
{
    "id" : "foo",
    "class" : "legs",
    "action" : "jump",
    "start_time" : 0.1
}
\end{lstlisting}

\noindent
Here we see an object with the \textit{id} ``foo,'' which is of \textit{class} type ``legs'', that has an attribute \textit{action} associated with it and a start time.

\subsection{Containers}
Symbols may also contain other symbols. 
Container symbols function to frame their contents, giving reference and context, like a plot graph frame, which provides a perspective and scaling for interpreting the set of data points displayed in the graph.

When a symbol contains other symbols, the child symbols are stored as an array in the object's \textit{contents} field. For example an imaginary class ``timeline'', which holds two types of leg actions, we might write something like:

\begin{lstlisting}[
belowskip=-2 \baselineskip,
  mathescape,
  columns=fullflexible,
  breaklines=true,
  basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont,
]
{
    "id" : "bar",
    "class" : "timeline",
    "duration" : 1,
    "contents" : [{
        "id" : "foo-1",
        "class" : "legs",
        "action" : "jump",
        "start_time" : 0.1
    },{
        "id" : "foo-2",
        "class" : "legs",
        "action" : "sit",
        "start_time" : 0.2
    }]
}

\end{lstlisting}

% move this to the definitions discussion?
In most cases, a symbol's mapping definition will require querying its parent symbol for information, in order to plot its data relative to the container context, for example offsetting the screen coordinate position based on the parent object position.

\section{Score File Format}\label{sec:score}

Using symbols and symbol containers, we can create tree structures which can be used to represent hierarchical grouping; to represent scores, or other types of data structures.
At the root of the tree structure is a top-level symbol, which might (but not necessarily) define behavior of its children objects.
Since the data elements are stored in js objects, it is easy to import/export \symbolist scores as JSON files.

When the application loads, it reads a default initialization file, in the form of a \symbolist score.
The current default initialization config file looks like this:

\begin{minipage}{\linewidth}
\begin{lstlisting}[
belowskip=-2 \baselineskip,
 language=Javascript,
  mathescape,
  columns=fullflexible,
  breaklines=true,
  basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont,
]
{
    "about" : "some metatdata",
    "id" : "Score",
    "class" : "RootSymbol",
    "tools" : [],
    "palette" : ["SubdivisionTool", "BasicSymbolGL"],
    "contents": { 
        "id" : "trio",
        "class" : "SystemContainer",
        "x": 200,
        "y": 100,
        "duration": 20,
        "time": 0,
        "contents" : [{
            "id" : "oboe",
            "class" : "FiveLineStave",
            "height" : 100,
            "lineSpacing" : 10,
            "duration": 20,
            "time": 0,
            "contents" : []
        },
        {
            "id" : "bassoon",
            "class" : "PartStave",
            "height" : 100,
            "time": 0,
            "duration": 20,
            "contents" : []
        },
        {
            "id" : "synth",
            "class" : "PartStave",
            "height" : 200,
            "time": 0,
            "duration": 20,
            "contents" : []
        }]
    }
}
\end{lstlisting}
\end{minipage}

The initialization file is literally a score object file, providing the default context for a given authoring situation. In this example, we can see there is a ``RootSymbol'', which contains a ``SystemContainer'', which in turn contains two ``PartStave'' symbols and one ``FiveLineStave'' symbol (which are all actually containers as well, initialized as empty arrays). The \textit{palette} and \textit{tools} attributes tell the application to provide access to certain tools, and child symbols in the GUI.

\section{Graphic Display Format}\label{graphic_display_format}

The graphic representation of the data in \symbolist uses SVG format, and and follows the same hierarchical structure of the data as found in the semantic data score object.
Since the new version of \symbolist uses a browser as a frontend, we are able to take advantage of the many standard tools and web functionalities provided by browsers for display, interaction and data management.

Like the JSON score initialization file above, the main application window is setup using HTML/CSS, and utilizing \drawsocket as a convenience wrapper to provide shorthand methods to create and manipulating browser window elements. 

\subsection{SVG}

The \symbolist format for an SVG \textit{symbol} is a one top group ($<$g$>$) elements, with two sub-groups for \textit{display} and \textit{contents}, using HTML/CSS class names. The most simple SVG symbol would be:

\begin{lstlisting}[
belowskip=-2 \baselineskip,
mathescape, columns=fullflexible, breaklines=true,basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont]
<g  id="foo" class="SymbolClassName symbol">
    <g class="SymbolClassName display"></g>
    <g class="SymbolClassName contents"></g>
</g>
\end{lstlisting}


Just like the semantic data objects, graphics objects have required \textit{id} and \textit{class} parameters, with an optional \textit{contents} element.

Each symbol grouping element is tagged using class names, following the symbol's unique class name (in this example ``SymbolClassName''). Note that the order is important: \textit{the symbol class type must be first}. The \textit{symbol} tag marks the top-level grouping object of the symbol, the \textit{display} element is a group that holds all of this symbol's visual display information, and the \textit{contents} is an group object for holding any potential child elements. Note that for simplicity, all \symbolist graphic elements include the \textit{contents} element as a placeholder.

\subsection{HTML}

Symbols and containers could also potentially be HTML elements instead of SVG. In the case of HTML you would use $<$div$>$ tags instead of SVG $<$g$>$:
html:

\begin{lstlisting}[
belowskip=-2 \baselineskip,
  mathescape,
  columns=fullflexible,
  basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont,
]
<div class="SymbolClassName symbol">
    <div class="SymbolClassName display"></div>
    <div class="SymbolClassName contents"></div>
</div>
\end{lstlisting}


\subsection{dataset-elements}\label{sec:dataset}

Since \symbolist is constantly mapping to and from semantic data and its graphic representation, we are using the HTML \textit{dataset} feature\footnote{https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/dataset} to store the semantic data inside the top-level \textit{symbol} element ($<$g$>$ or $<$div$>$).
The HTML dataset attributes use the prefix ``\textit{data-}''.\footnote{Note that according to the HTML dataset specifications, all names will be converted to lowercase, this can create issues in some cases, so best practice is to use all lowercase for attribute names.}

For example, mapping our imaginary ``legs'' actions above, the corresponding SVG objects would be (skipping the actual display drawing for now):

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=Javascript,
belowskip=-2 \baselineskip,
%float=*,
mathescape, columns=fullflexible, breaklines=true,basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont]
<g  id="bar" class="Timeline symbol" data-duration="1">
  <g class="Timeline display"></g>
  <g class="Timeline contents">
      <g  id="foo-1" class="Legs symbol" data-action="jump" data-start_time="0.1">
        <g class="Legs display"></g>
        <g class="Legs contents"></g>
      </g>
      <g  id="foo-2" class="Legs symbol" data-action="sit" data-start_time="0.2">
        <g class="Legs display"></g>
        <g class="Legs contents"></g>
      </g>
    </g>
</g>
\end{lstlisting}
\end{minipage}




\section{Performing Data}

Just as the \textit{graphic representation} can be seen as a visual expression of \textit{semantic data}, the same semantic data can also used as control data in connection with other media forms. For example, a \textit{note} object's pitch, onset, and duration information could be used to trigger a note on a synthesizer, or a sequence of Labanotation~\cite{guest2014labanotation} could be used to guide the movement of robotic motors, create haptic feedback for live performance~\cite{west2019design}, and so on. 

\symbolist provides several different options for sorting and looking up data (see Figure~\ref{fig:score-lookup}), which can serve as a structure for the performance of a ``score'', or other data formats. Typically, some representation of time is used to indicate an object's moment of action, but in \symbolist the exact nature of the temporal organization is up to to the author.

In addition to the \textit{semantic} and \textit{graphic} contexts of data representation, we can think of the \textit{performance} of the data as a third data context context.

\section{Mapping}\label{sec:mapping}

Between each of these representation contexts there is a layer of mapping, with the \textit{semantic data} serving as the primary representation type. 

\textit{Semantic data to graphic representation} mapping (Figure~\ref{fig:data-to-graphic}) is used for the creation of graphic symbols from a stream of input, for example from generative processes, textural authoring, or computer assisted composition systems~\cite{bresson2011om, didkovsky2008maxscore, agostini2015max, baca2015abjad, burloiu2017visual}.

\textit{Graphic representation to semantic data} mapping (Figure~\ref{fig:graphic-to-data}) is used in order to create or edit data based on graphic information. This is the typical ``graphical user interface'' situation, where the data is accessible through its visual representation.

\textit{Semantic data to performance media} mapping (Figure~\ref{fig:score-lookup}) is the use of the data as a sequence of events that can be played in time (or used to control other processes not necessarily in time).

Note that in \symbolist mapping between \textit{performance media} and \textit{graphic representation} is achieved through first mapping to semantic data. See section~\ref{library_definitions_api} for further discussion.


% mapping figures

\begin{figure}[ht!]
\centering
\includegraphics[width=0.9\columnwidth]{data-to-graphic.pdf}
\caption{\textit{semantic data} mapped to create a \textit{graphic} representation from input data.
\label{fig:data-to-graphic}}
\end{figure}

\begin{figure}[ht!]
\centering
\includegraphics[width=0.9\columnwidth]{graphic-to-data.pdf}
\caption{If edited graphically, the updated graphic data is then mapped back to \textit{semantic data} representation. 
\label{fig:graphic-to-data}}
\end{figure}

\begin{figure}[ht!]
\centering
\includegraphics[width=1\columnwidth]{score-lookup.pdf}
\caption{Using the lookup method defined by the symbol class, the \textit{semantic data} can be used to perform external instruments via Open Sound Control. 
\label{fig:score-lookup}}
\end{figure}

\section{Symbol Definitions}\label{library_definitions_api}
%Definition scripts are composed as Javascript modules which are loaded into the program at runtime.

Symbols are defined as Javascript classes which are stored and recalled when symbol actions are performed. 
For each user interaction, the ui- and io-controllers looks up the symbols involved in the interaction, and uses their definitions to enact the symbol's reaction. 
Definitions define the mapping relationships between the symbol's \textit{semantic}, \textit{graphic}, and output \textit{performance} data.
Through creating definitions, users are able to form libraries of symbols that can be used together to fit the tools and representation structure needed to address a given use-case scenario.
%Definitions allow for custom graphical user interaction for each type of symbol, and are used to define mapping relationships between the symbol's \textit{semantic}, \textit{graphic}, and output \textit{performance} data.

To allow for maximum flexibility of interaction and the creation of context-specific composition environments, each symbol manages its own mouse interaction, triggered by the user's selection in the palette toolbar. 
In order to streamline the process of writing new symbol definitions there is a template base class that handles most common interaction situations, which can be redefined and overwritten by sub-classes. Eventually it is planned to provide a UI in the editor for defining a mapping definition graphically, but this is not yet implemented.

There are two types of definition scripts:
\begin{itemize}\itemsep0pt 
\item \textit{ui-definitions} run in the \uicontroller and perform user interactions based on the different interaction modes described above, and apply bidirectional mapping between semantic data representation and graphic representation in the browser.
\item \textit{io-definitions} run in the \iocontroller and are used to assist in the lookup and \textit{performance} mappings of the semantic data to media like sound synthesis, video, etc., or to perform server-side score manipulations.
\end{itemize}

In each controller context there are certain methods and variables that need to be defined in order for the class to function properly in the \symbolist ecosystem.

%Currently, the system uses the same .js file to hold both the `ui` and `io` definitions. To aid in development there is a template file that can be used to handle most of the most common actions.

%
%\subsection*{IO and UI data access scope}\label{sec:io_ui_elements}
%
%Since the \textit{ui} and \textit{io} controllers are run in separate processes\footnote{and potentially separate devices.} (Figure~\ref{fig:architecture}), there is no direct access to data stored in the other location. In other words, the \iocontroller does not have direct access to the symbol's drawing information, and the \uicontroller does not have direct access to the score or UDP port for sending OSC message.
%
%Loosely following the MVC pattern,\footnote{https://developer.mozilla.org/en-US/docs/Glossary/MVC} the concerns of drawing are kept within the browser-side \uicontroller, with all messages between the \textit{ui} and \textit{io} processes are in \drawsocket JSON format, with all symbol data expressed in its \textit{semantic} form.
%Meanwhile the \iocontroller manages the \textit{score} and handles external OSC communication, relaying messages to the \uicontroller as needed.
%
%As discussed above, the graphic representation takes advantage of the HTML dataset feature, which provides a mechanism for storing the semantic data inside the graphic context (see section~\ref{sec:dataset}).
%Since ui-definitions are running in a web-browser, they are able to make use of the standard HTML-DOM JS methods for fast querying of elements (i.e. querySelector, getElementById, etc.)\footnote{https://developer.mozilla.org/en-US/docs/Web/API/Document} to retrieve graphic as well as semantic data stored in the display hierarchy.
%
%To provide similar data query access in the \iocontroller, the score data is stored in two JS objects: the \textit{score}, which stores the semantic data in a hierarchical tree structure, and a object named \textit{model}, which is a flat lookup table by unique id, with links to object references to the coordinated object in the score tree.
%
%Since the ui- and io-controllers run in parallel they need to keep the other side updated in case of any alteration to the score data. 
%Updates sent from the \iocontroller to the UI can be as simple as sending a new score which will trigger a redrawing of the graphics in the UI view. 
%Updates from graphic user interaction require mapping from the graphic to semantic representation, which is handled in the browser. Any changes are sent back to the \iocontroller where the new semantic values are updated in the \textit{model} (which automatically update the \textit{score}, since both objects hold JS references to the same JS objects).
%
\subsection*{API Functions}\label{sec:api_functions}

In each controller context, there are a set of helper functions for use by symbol definitions stored in global objects called \uiapi and \ioapi, which provide many essential operations.

\section{UI Definitions}\label{sec:ui_callbacks}

At the time of writing, the variables and methods defined in the symbol class referred to by the \uicontroller are:

\begin{itemize}\itemsep0pt 
\item \textit{class}: the unique name of the symbol, used to store and lookup the symbol definition in the \uicontroller.

\item \textit{palette}: in the case of container symbols, an array of class names of other symbols that can be used within this container, which are drawn in the palette toolbar when the user selects a symbol as a new context.

\item \textit{getPaletteIcon}: called when drawing the palette for a given container; returns an icon for display in the palette toolbar, using \drawsocket format.

\item \textit{paletteSelected}: called when the user clicks on the palette icon for this symbol, used to trigger custom UI. When the symbol is selected in the palette, the definition should enable its mouse handers. For creating new symbols from mouse data (currently \textit{cmd-click} is the convention).

\item \textit{getInfoDisplay}: called when creating the inspector window; returns drawing commands for the inspector contextual menu, for convenience \uiapi provides a function called \textit{makeDefaultInfoDisplay} which can be used in most cases.

\item \textit{fromData}: called when data is should be mapped to graphic representation. The definition is responsible for creating the graphic element, normally via \drawsocket, but other approaches are also possible.

\item \textit{updateFromDataset}: called from the inspector when elements of the data should be updated. Usually this function will call \textit{fromData} to redraw the graphic symbol, and should also send the updated data to the server.

\item \textit{selected}: called on selection and deselection, return true if selection is handled in the script, returning false (or no return) will trigger the default selection mechanics by the \uicontroller.

\item \textit{drag}: called from \uicontroller when the user drags selected symbols. For best results, the use the \uiapi \textit{translate} function to set the symbol's SVG translation matrix, but do not apply the translation until mouse up to avoid incremental state changes to score.

\item \textit{applyTransformToData}: called on mouse-up if selected objects have changed. Definition should then apply the transform matrix to the SVG attribute values. This is important because the attribute values not the translation matrix are used for mapping. The \uiapi helper function \textit{applyTransform} is provided for convenience.

\item \textit{currentContext}: called when the user enters or exits a container symbol (hitting the [s] key, [esc] to exit).

\item \textit{editMode}: called when entering and exiting edit mode.
\end{itemize}

\subsection{Data and View Parameters}\label{sec:view-parameters}

Probably the most important elements of the symbol definition is the bi-directional mapping between semantic and graphic forms.
 
Looking at Figures~\ref{fig:data-to-graphic} and \ref{fig:graphic-to-data} we can see that in some cases the relationship between a semantic property and its graphic representation is not a one-to-one mapping.
For instance in Figure~\ref{fig:data-to-graphic} the \textit{note} property needs to be mapped to a pixel position that is used for both the center point of a graphic circle (note-head) as well as the starting point for a line (duration indication).
In reverse, Figure~\ref{fig:graphic-to-data} shows how when the user moves a symbol graphically, the new pixel positions need to be translated back into semantic data in order to update the score.
This can get somewhat complex in cases of nonlinear mappings and hierarchical data structures.

In order to manage the mapping between semantic and display representation, the template base class uses an intermediate mapping stage called \textit{view-parameters}.
The idea is that the \textit{view-parameter} stage contains the bare-minimum number of variables needed to draw the symbol.

For example, in Figure~\ref{fig:data-to-graphic} the graphic representation requires a \textit{y} position relative to the pitch, an \textit{x} position relative to the start time, and a \textit{width} value relative to the duration of the event (the amplitude is not displayed).
After first mapping from the semantic attributes \textit{note}, \textit{start-time} and \textit{duration} to view-parameters \textit{x}, \textit{y}, and \textit{width}, the drawing method can then use the \textit{x}, \textit{y}, and \textit{width} values to draw its two graphic objects from the reduced set of view-parameters values.

The ui template class uses two functions to define data-view mappings: \textit{dataToViewParams} which receives the semantic data object and returns the view-parameter object, and \textit{viewParamsToData} which performs the opposite mapping.
Note that in many cases the \textit{viewParamsToData} function needs only one aspect of the graphic to map back to semantic data. In the example shown in Figure~\ref{fig:graphic-to-data}, the mapping only really needs either the center point of the note-head or the start-x position of the line to determine the \textit{start-time} parameter.

The template class also two additional data/view parameter translation methods to coordinate child objects with parent containers: \textit{childDataToViewParams} and \textit{childViewParamsToData}.
For example, in Figures~\ref{fig:data-to-graphic} a note-head circle is drawn from its \textit{note} parameter, in coordination with a five-line staff.
Like a plot graph, the \textit{staff} is a container symbol which defines how we interpret the elements written on its lines. 
In this case, the symbol definition for the \textit{staff} has a \textit{childDataToViewParams} function is called by the action of the child symbol. 
The \textit{childDataToViewParams} receives the child data object, as well as the graphic element of a particular staff (which was selected by the user pressing the [s] key). Given its placement on the screen and its own data parameters (number of lines, clef, etc.) the staff's \textit{childDataToViewParams} function will return the view parameters for the child, mapped in relationship to the container object.
Similarly, when the graphic object is moved, the child object will call the parent's \textit{childViewParamsToData} function to assist with mapping back to semantic data format.


\section{IO Definitions}\label{sec:io_definitions}

At the time of writing, the \iocontroller has a much simpler function, which is to handle OSC messages from external applications, score data maintenance, file reading and writing, and responding to external score lookup queries for sequencing.
Variables and methods currently used by the \iocontroller are:

\begin{itemize}\itemsep0pt 
\item \textit{class}: class name, corresponding to class name in UI Definition, used to store and lookup the symbol definition.

\item \textit{comparator}: a comparator function used in container symbols to sort child symbol. For example, if a given container uses a \textit{time} value for sorting, when a new child node is added, the comparator function helps the container insert the child element at the correct location in the \textit{contents} array. This assists to increase the efficiency of looking up events occurring at a given time (or other data sequencing parameter).

\item \textit{lookup}: called via OSC (using the \drawsocket syntax \textit{key} ``lookup'') to look up events at a given value specified by the container (e.g. typically \textit{time}). The \textit{lookup} function performs hit detection collecting all active elements at that query point, output back to the calling application via OSC (the in/out UDP port information is set in the \symbolist configuration file). By default the output is an array of all active data objects at the lookup point, along with the relative phase position within each element, useful for controlling amplitude envelopes etc. (See Figure~\ref{fig:score-lookup}).

\item \textit{getFormattedLookup}: called via OSC to request a complete list of events for external sequencing, formatted in the symbol definition to apply to the external syntax requirements.
%For example, this function might return a list of \textit{/x} and \textit{/y} values for use with the \textit{o.lookup$\sim$} Max object, or create a MIDI file export etc.
% references for o.lookup? or maybe take this out, too specific

\end{itemize}

Note that the \textit{lookup} and \textit{getFormattedLookup} methods are able to view the whole OSC bundle that is sent in, and have access to the entire score data model, and so it is also possible to define multiple ways of looking up (and performing) the score data at the same time; or example multidimensional nearest neighbor lookup, or polytemporal sequencing, etc.

%all parameters included in the input \drawsocket syntax \textit{val} object will be included in the data received by \textit{lookup} and \textit{getFormattedLookup} as a parameters, and can then be used when performing the lookup, for example to perform multidimensional nearest neighbor lookup, etc.
\section{Creating Symbols from OSC input}\label{sec:osc_input}

As an illustration of how data is processed through the \symbolist architecture, we can follow the sequence of actions taken in the case of \textit{semantic to graphic} mapping; for example when algorithmically generating score data, using an outside process to create the data and sending it to \symbolist via OSC, using the \drawsocket key/val syntax.

\subsubsection*{Data input via OSC}
The \iocontroller has a small collection of built-in processes that can be called via OSC, the most important of which is the function to add new data elements to the score and graphic display, accessible using the \textit{data} keyword.

For example, here is an OSC bundle using the \textit{data} key:
\begin{lstlisting}[  language=Javascript, 
belowskip=-2 \baselineskip,
mathescape, columns=fullflexible, basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont ]
{
    /key : "data",
    /val : {
        /class : "FiveLineStaveEvent",
        /id : "foo"
        /container : "oboe",
        /time : 0.13622,
        /ratio : "7/4",
        /duration : 0.1,
        /amp : 1
    }
  }
\end{lstlisting}

The ``data'' keyword message has the following required and optional attributes:
\begin{itemize}\itemsep0pt 
  \item \textit{class}: the class name of the object to create (required) .
  \item \textit{container}: the \textit{id} of the container symbol class to put the object in (required).
   \item \textit{id}: a unique id to use for the data object (optional); if not specified a unique string will be generated .
  \item Other required or optional parameters will depend on the symbol definition.
\end{itemize}

Upon receiving an OSC message with the \textit{key} ``data'', the object payload stored by \textit{val} is added to the model, and then relayed to the \uicontroller.

% this is the second part of the process:

\subsubsection*{Data to View Mapping in the \uicontroller}

Received by the \uicontroller, the semantic data then is mapped to graphic data, by looking up the symbol's \textit{class} definition and calling the ui-definition's \textit{fromData} method, which maps from the data representation to the graphic drawing commands. 

As discussed above (in Section~\ref{sec:view-parameters}), when using the symbol template base-class, the \textit{fromData} method will usually call the symbol's internal \textit{dataToViewParams} which performs the mapping from semantic to a minimal set of graphic values which are then used to draw the graphics, by sending drawing commands to \drawsocket accessed through the \uiapi, including the HTML dataset storage, as described above (in Section~\ref{graphic_display_format}).

A typical drawing command would look something like:
%1. send the drawing commands to the browser display (via \drawsocket usually, using the `drawsocketInput` API method). Include the data content into the symbol by using the HTML `dataset` (you can use `ui\_api.dataToHTML(dataObj)` helper function to create the `data-` tags)

\begin{lstlisting}[ language=Javascript,
belowskip=-2 \baselineskip,
]
    ui_api.drawsocketInput({
        key: "svg",
        val: {
            class: `${className} symbol`,
            id: uniqueID,
            parent: container.id,
            ...newView, 
            ...ui_api.dataToHTML(dataObj)
        }
    }) 
\end{lstlisting}

\noindent
Here, we use the JS spread operator ``\ldots'' to merge the \textit{newView} variable, holding \drawsocket format SVG data, and the HTML dataset information, encoded via the \uiapi \textit{dataToHTML} helper function into the \textit{val} object with the associated ``svg'' \drawsocket keyword. The object is then sent to \drawsocket via the \uiapi \textit{drawsocketInput} helper function to be added to the browser screen.


\section{Custom User Methods}\label{sec:user_methods}

Users may also create their own additional methods in either ui or io-definitions and call them from outside processes over OSC, or from other symbol definitions, using the ``call'' keyword.\footnote{\symbolist will pass the same call request to both definitions, so if both have a function of the same name they will both be called.}

As elsewhere, \symbolist uses \drawsocket syntax, and requires two parameters  in the \textit{val} object need to lookup and execute the method:

\begin{itemize}\itemsep0pt 
 \item \textit{class}: name of the class to lookup.
  \item \textit{method} name of class method to call.
\end{itemize}

All of the parameters in the \textit{val} object will be passed to the function as an argument. 

User class methods can be used to apply operations to the score or ui, for example transposing all pitches on the ``Staff'' named ``oboe'' might look like this:

\begin{lstlisting}[language=Javascript,
belowskip=-2 \baselineskip,
  mathescape,
  columns=fullflexible,
  basicstyle=\oscfontsize\fontfamily{lmvtt}\selectfont,
]
{
    /key : "call",
    /val : {
        /class : "Staff",
        /method : "transpose",
        /id : "oboe"
        /steps : 12
    }
}
\end{lstlisting}

On receiving this OSC bundle, the \iocontroller will lookup the class ``Staff'' and attempt to call its method ``transpose'', passing the entire \textit{val} object to the symbol method as an argument. The user-defined ``transpose'' function might then do something like lookup the ``oboe'' staff in the model, and then iterate all of its contents, offsetting the ``note'' values by the number of steps specified in the method arguments.

%%%%%
% screenshot
%\begin{figure*}[ht!]
%\centering
%\includegraphics[width=1.5\columnwidth]{nodescore.png}
%\caption{ \symbolist screenshot, showing some different types of staves, and editing capabilities.
%\label{fig:nodescore}}
%\end{figure*}

\section{Conclusions} % and Future Developments
 
With the new symbol class definition system in place, initial experiments indicate that this new experimental \symbolist implementation should be able to handle a very wide variety of score and symbol structures, and provide the mechanisms for users to compose bi-directional mappings between semantic and graphic representation.
The system seems to have a potential for many applications in digital media compositional practice, and may someday evolve into a fully functional authoring environment for computer performable symbolic notation.

In order to further evaluate the robustness of the system, the next step will be to go through the process of developing complete definition libraries for working with different types of notation systems. As a test case, currently one of the PhD students at the HfMT Hamburg has been working on a set of definitions for common practice notation, which is planned for presentation at the 2023 TENOR conference, along with other experimental approaches.

One challenge that may need to be addressed is the ease or difficulty there is in creating new symbol definitions. At the moment the system is based in Javascript, which means that the user must program the definitions with textural code. However, as a graphic oriented authoring environment, it would be convenient if there were some way to create new symbol definitions graphically, or at least within the \symbolist graphical environment. 
In the process of creating test definition libraries, further research is planned to develop a GUI for symbol definitions, and if possibly streamline the process of bidirectional mapping. For example, most mathematical operations have an inverse operation, and so perhaps there could be a GUI interface that provides tools to define both mapping directions simultaneously.

The Electron framework is currently working well for cross platform app development, however there have been some issues that came up after Electron version 12 which introduced new security measures, including context isolation\footnote{https://www.electronjs.org/docs/latest/tutorial/context-isolation}, and increase limitation of the using the require function to import user libraries. In order to function in a web-safe way, \symbolist is currently using Webpack\footnote{https://webpack.js.org/} to bundle the JS classes into a single file that is loaded on startup. Previously, users were able to dynamically load symbol definitions at run time, which seems like a more natural application working model. 
However, since \symbolist is now browser-based and using the same system as \drawsocket for dynamic graphic rendering, there is also the possibility of networked use of \symbolist, for example, in connection with a graphic multitouch interface (iPad etc.), it would be possible to interact with \symbolist over a network, and therefore possibly the web-security measures are important. 
More testing is needed to determine which features are the most important.

For playback/sequencing of \symbolist scores, currently users can send either the \textit{lookup} or \textit{lookupFormatted} messages to the \iocontroller, which will then respond with data that can be used to perform the score in another software like Max, Pd, SuperCollider, etc.
The lookup is currently implemented in Javascript, which is not the fastest or most temporally precise method of playing back the score.
As a starting point, a Max external called \textit{o.lookup$\sim$}, which accepts a list of x and y coordinate points and reads through the sequence of points via a sample-rate phase input.
This system works quite will for single data sequences (i.e. value of $y$ at point $x$), however for more robust playback, it might be worthwhile to develop a C/C++ based database lookup system, which could provide optimized getter methods for data playback. 
For example, this might take the form of a Max external that can read a \symbolist score and provide optimized access for playback (possibly updated in realtime via connection to the \symbolist server).
Or even further, it could be imagined that a score could be exported to playback in a DAW like Ableton Live.
It could also be possible to attach links to other OSC sequencing applications like IRCAM's Antescofo expression language\cite{giavitto2017time}.

Other development directions that may be interesting to pursue would be to integrate other frameworks into the application.
Some first steps for 3D graphics have begun with the introduction of the three.js\footnote{https://threejs.org/} library, visible in the rotated cubes in Figure~\ref{fig:screenshot}, however more work is needed to provide tools for manipulating 3D graphics.
In the area of notation for spatial movement, there are plans to continue development of trajectories (visible in the curves attached to note events in Figure \ref{fig:screenshot}, and to connect \symbolist with the ICST's Spatialization Symbolic Music Notation (SSMN)\cite{ellberger2014spatialization}.

In the audio domain, it could be interesting to develop tools for development of signal processing graphs that could be interpreted and performed in other applications, for example generating Faust\footnote{https://faust.grame.fr/} or Gen$\sim$ DSP code.%, SuperCollider instruments etc. %, or even potentially creating connections with other web-based visual programming interfaces like purr-data\footnote{https://git.purrdata.net/jwilkes/purr-data} and cables.gl\footnote{https://cables.gl/}.

There are very many possibilities for the future development of \symbolist, and so far it seems that the framework is providing a solid ground for the creation of new authoring environments. In a way, \symbolist is a meta-environment, an application that aims to ease the process of creating new authoring environments.
Like the creation of a new instrument, the challenge then is to work through the difficulties of creating the instrument, so that the instrument can be learned to play, and then, finally, the instrument can be used for the creation of new kinds of art.

\begin{acknowledgments}

A special thanks to James Tsz-Him Cheung for his work on the common practice notation definitions, which is greatly helping push \symbolist forward, and especially thank you to Prof. Dr. Georg Hajdu for his collaboration and ongoing support for this work.

\end{acknowledgments} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%bibliography 
\balance % balance the columns on the last page
\bibliography{symbolist}
\end{document}



%In this paper we present a case study for the creation of an open system for graphically developing symbolic notation which can function both as professional quality print or online documentation, as well as a computer performable score in electro-acoustic music and other computer aided contexts. Leveraging Adobe Illustrator‚Äôs graphic design tools and support for the Scalable Vector Graphics (SVG) file format~\footnote{https://www.w3.org/TR/SVG11/}, the study shows that SVG, being based on Extensible Markup Language (XML), can be similarly used as a tree-based container for score information. In the study, OpenSoundControl (OSC)~\cite{wright:osc}  serves as middleware used to interpret the SVG representation and finally realize this interpretation in the intended media context (electronic music, spatial audio, sound art, kinetic art, video, etc.). The paper discusses how this interpretive layer is made possible through the separation of visual representation from the act of rendering, and describes details of the current implementation, and outlines future developments for the project.
